{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Lab3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eld2H4Yj8aii"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_data(task):\n",
        "    if task == \"3.1\":\n",
        "        x1 = [-1, -1, 1, -1, 1, -1, -1, 1]  # [-1., -1., 1., -1., 1., -1., -1., 1.]\n",
        "        x2 = [-1, -1, -1, -1, -1, 1, -1, -1]  # [-1., -1., -1., -1., -1., 1., -1., -1.]\n",
        "        x3 = [-1, 1, 1, -1, -1, 1, -1, 1]  # [-1., 1., 1., -1., -1., 1., -1., 1.]\n",
        "        memory_patterns = [x1, x2, x3]\n",
        "        x1d = [1, -1, 1, -1, 1, -1, -1, 1] # [1., -1., 1., -1., 1., -1., -1., 1.]\n",
        "        x2d = [1, 1, -1, -1, -1, 1, -1, -1] # [1., 1., -1., -1., -1., 1., -1., -1.]\n",
        "        x3d = [1, 1, 1, -1, 1, 1, -1, 1]#[1., 1., 1., -1., 1., 1., -1., 1.]\n",
        "        test_patterns = [x1d, x2d, x3d]\n",
        "        x1dd = [1, 1, -1, 1, 1, -1, -1, -1]\n",
        "        x2dd = [1, 1, -1, 1, 1, 1, 1, -1]\n",
        "        x3dd = [1, -1, 1, 1, 1, -1, -1, 1]\n",
        "        dissimilar_patterns = [x1dd, x2dd, x3dd]\n",
        "        return np.array(memory_patterns), np.array(test_patterns), np.array(dissimilar_patterns)\n",
        "\n",
        "\n",
        "    data = np.fromfile(\"pict.dat\",sep=\",\")\n",
        "    pict = np.zeros((11, 1024))\n",
        "    #img = np.zeros((11, 32, 32))\n",
        "    for k in range(11):\n",
        "        pict[k, :] = data[k*1024:(k+1)*1024]\n",
        "        #img[k,:] = pict[k].reshape(32,32)\n",
        "\n",
        "    if task == \"3.2\":\n",
        "        #visualize_img(pict[0:3], [\"p1\", \"p2\", \"p3\"])\n",
        "        return pict[0:3], pict[9:11]\n",
        "\n",
        "    if task == \"3.4\":\n",
        "        # add noise\n",
        "        gaussian_noise = np.random.normal(0, 2, 1024)#(1024,)\n",
        "        pict_with_noise = []# 3 * 7 * 1024\n",
        "        noise_percent = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
        "        for percent in noise_percent:\n",
        "            with_noise = []\n",
        "            for i in range(3):\n",
        "                noise = np.zeros(1024)\n",
        "                noise[0: int(1024*percent)] = gaussian_noise[0: int(1024*percent)]\n",
        "                np.random.shuffle(noise)\n",
        "                with_noise.append(noise+pict[i])\n",
        "            #visualize_img(np.array(with_noise),[\"p1 with {}% noise\".format(percent*100), \"p2 with {}% noise\".format(percent*100), \"p3 with {}% noise\".format(percent*100)])# visualization\n",
        "            pict_with_noise.append(np.array(with_noise))\n",
        "        return pict[0:3], np.array(pict_with_noise)\n",
        "\n",
        "    if task == \"3.5\":\n",
        "        return pict[0:7],\n",
        "\n",
        "def visualize_img(pict, info=None):\n",
        "    plt.figure()\n",
        "    num = pict.shape[0]\n",
        "    if num==1:\n",
        "        img = pict[0].reshape(32, 32)\n",
        "        plt.imshow(img)\n",
        "        plt.title(info[0])\n",
        "    else:\n",
        "        f, ax = plt.subplots(1, num)\n",
        "        for i in range(num):\n",
        "            img = pict[i].reshape(32, 32)\n",
        "            ax[i].set_title(\"{}\".format(info[i]))\n",
        "            ax[i].imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "class Hopfield_network():\n",
        "    def __init__(self, dim):\n",
        "        self.W = None\n",
        "        self.dim = dim\n",
        "        self.max_iter = 1000\n",
        "\n",
        "    def weight_update(self, X):\n",
        "        self.W = np.zeros((self.dim, self.dim))\n",
        "        for i in range(X.shape[0]):\n",
        "            self.W += np.dot(X[i].reshape(-1, 1), X[i].reshape(-1, 1).T)\n",
        "        #self.W /= self.dim\n",
        "\n",
        "    def weight_symmetric(self):\n",
        "        self.weight_normal()\n",
        "        self.W = 0.5 * (self.W + self.W.T)\n",
        "\n",
        "    def weight_normal(self):\n",
        "        self.W = np.random.normal(0, 1, (self.dim, self.dim))\n",
        "\n",
        "    def energy(self, init_state):\n",
        "        wst = np.dot(self.W, init_state)\n",
        "        return -np.dot(init_state.T, wst)[0][0]\n",
        "\n",
        "    def sync_update(self, init_state):\n",
        "        old_state = np.copy(init_state)#(1024,1)\n",
        "        new_state = np.zeros((init_state.shape[0], old_state.shape[1]))\n",
        "        it = 0\n",
        "        while(it < self.max_iter):\n",
        "            #wx =  #(1024, 1)\n",
        "            new_state = self.sign(np.dot(self.W, old_state))#.reshape(1, -1)) #(1024,1)\n",
        "            #print(new_state)\n",
        "            if np.equal(new_state, old_state).all() == True:\n",
        "                old_state = np.copy(new_state)\n",
        "                print(\"Synchronous: Converge in {} iterations\".format(it))\n",
        "                break\n",
        "            old_state = np.copy(new_state)\n",
        "            it += 1\n",
        "        #print(\"Cannot converge in {} iterations\".format(self.max_iter))\n",
        "        return old_state.reshape(1, -1)[0]\n",
        "\n",
        "    def asyn_update(self, init_state, show_energy=False):\n",
        "        old_state = np.copy(init_state)\n",
        "        new_state = np.zeros((init_state.shape[0], old_state.shape[1]))\n",
        "        self._trace = [[], []]\n",
        "        for i in range(self.max_iter):\n",
        "            if show_energy == True:\n",
        "                print(\"iteration\", i, \" --- \", self.energy(old_state))\n",
        "            index = np.random.randint(0, self.dim, self.dim)\n",
        "            for j in range(self.dim):\n",
        "                new_state[index[j]] = self.sign(np.dot(self.W[index[j]], old_state))\n",
        "            if np.array_equal(new_state, old_state):\n",
        "                old_state = np.copy(new_state)\n",
        "                print(\"Asynchronous: Converge in {} iterations\".format(i))\n",
        "                return old_state.reshape(1, -1)[0]\n",
        "            old_state = np.copy(new_state)#(1024,1)\n",
        "            #if i % 100 == 0:\n",
        "                #visualize_img(np.array([old_state.reshape(1, -1)[0]]), [\"{} iterations\".format(i)])\n",
        "        print(\"Cannot converge in {} iterations\".format(self.max_iter))\n",
        "        #visualize_img(np.array([old_state.reshape(1, -1)[0]]), [\"converge at {} iterations\".format(i)])\n",
        "        return old_state.reshape(1, -1)[0]\n",
        "\n",
        "    def sign(self, wx):\n",
        "        #return np.sign(wx)\n",
        "        return np.where(wx<=0, -1, 1)\n",
        "\n",
        "    def check_attractions(self, init_state):\n",
        "        state = self.sign(np.dot(self.W, init_state).reshape(1, -1))\n",
        "        return np.equal(state, init_state).all()\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Main\n",
        "\"\"\"\n",
        "\"\"\"3.1\"\"\"\n",
        "\n",
        "train, test, test_2 = get_data(\"3.1\")\n",
        "net = Hopfield_network(train.shape[1])\n",
        "net.weight_update(train)\n",
        "for i in range(test.shape[0]):\n",
        "    output = net.sync_update(test[i].reshape(-1, 1))#(8, 1)\n",
        "    print(\" Input: {}; \\n Output: {}; \\n Stored: {}.\\n\".format(test[i], output, train[i]))\n",
        "# find all attractions\n",
        "count = 0\n",
        "for j in range(256):#2^8\n",
        "    ele = np.array([(j >> y & 1) for y in range(8 - 1, -1, -1)])\n",
        "    state = np.where(ele==1, 1, -1)\n",
        "    if net.check_attractions(state):#(8,)\n",
        "        count += 1\n",
        "        print(state)\n",
        "print(\"#attractions = \", count)\n",
        "# test more dissimilar starting pattern\n",
        "for i in range(test_2.shape[0]):\n",
        "    output = net.sync_update(test_2[i].reshape(-1, 1))# (8, 1)\n",
        "    print(\" Input: {};  Output: {}\".format(test_2[i], output))\n",
        "\n",
        "\n",
        "\"\"\"3.2\"\"\"\n",
        "'''\n",
        "train, test = get_data(\"3.2\")\n",
        "net = Hopfield_network(train.shape[1])\n",
        "net.weight_update(train)\n",
        "res1 = []\n",
        "for i in range(test.shape[0]):\n",
        "    output = net.sync_update(test[i].reshape(-1, 1))#(1024,1)\n",
        "    res1.append(output)\n",
        "visualize_img(np.array([test[0],res1[0], test[1],res1[1]]), [\"p10\", \"updated p10\", \"p11\", \"updated p11\"])\n",
        "# select units randomly\n",
        "res2 = []\n",
        "for i in range(test.shape[0]):\n",
        "    output = net.asyn_update(test[i].reshape(-1, 1))#(1024,1)\n",
        "    res2.append(output)\n",
        "visualize_img(np.array([test[0],res2[0], test[1],res2[1]]), [\"p10\", \"after\", \"p11\", \"after\"])\n",
        "'''\n",
        "\n",
        "\"\"\"3.3\"\"\"\n",
        "'''\n",
        "# energy at the different attractions\n",
        "train, test = get_data(\"3.2\")\n",
        "net = Hopfield_network(train.shape[1])\n",
        "net.weight_update(train)\n",
        "for i in range(train.shape[0]):\n",
        "    print(\"energy at p{}: \".format(i+1), net.energy(train[i].reshape(-1, 1)))\n",
        "# energy at the points of the distorted patterns\n",
        "for i in range(test.shape[0]):\n",
        "    print(\"energy at p{}: \".format(i+10), net.energy(test[i].reshape(-1, 1)))\n",
        "# how energy changes from iteration to iteration in sequential update rule\n",
        "for i in range(test.shape[0]):\n",
        "    print(\"energy change in p{}: \".format(i+10))\n",
        "    output = net.asyn_update(test[i].reshape(-1, 1), show_energy=True)\n",
        "# normally distributed random weight\n",
        "net.weight_normal()\n",
        "for i in range(test.shape[0]):\n",
        "    print(\"energy change in p{} with randomly normal weight matrix\".format(i+10))\n",
        "    output = net.asyn_update(test[i].reshape(-1, 1))\n",
        "# symmetric weight matrix\n",
        "net.weight_symmetric()\n",
        "for i in range(test.shape[0]):\n",
        "    print(\"energy change in p{} with symmetric weight matrix\".format(i+10))\n",
        "    output = net.asyn_update(test[i].reshape(-1, 1))\n",
        "'''\n",
        "\n",
        "\"\"\"3.4\"\"\"\n",
        "'''\n",
        "# how much noise can be removed\n",
        "train, test = get_data(\"3.4\")\n",
        "net = Hopfield_network(train.shape[1])\n",
        "net.weight_update(train)\n",
        "acc = np.zeros((10, 3))\n",
        "for m in range(50):\n",
        "    train, test = get_data(\"3.4\")\n",
        "    for i in range(test.shape[0]): # 10 noise\n",
        "        print(\"Adding {}% noise to the patterns\".format((i+1)*10))\n",
        "        res1 = []\n",
        "        for j in range(test.shape[1]): # 3 patterns\n",
        "            output = net.sync_update(test[i][j].reshape(-1, 1))\n",
        "            if np.equal(output, train[j]).all() == True:\n",
        "                acc[i, j] += 1\n",
        "        #print(\"recover rate of p{0} with {1}% noise: {2}\".format(j + 1, (i + 1)*10, acc/50))\n",
        "print(acc/50)\n",
        "            #res1.append(output)\n",
        "        #visualize_img(np.array([test[i][0], res1[0], test[i][1], res1[1], test[i][2], res1[2]]), [\"{}% noise\".\\\n",
        "                      #format((i+1)*10),\"result\", \"{}% noise\".format((i+1)*10),\"result\", \"{}% noise\".format((i+1)*10),\"result\"])\n",
        "'''\n",
        "\"\"\"3.5\"\"\"\n",
        "# how many patterns could be safely stored\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDJ2IoV5ZOZw",
        "outputId": "ebe56534-ef34-453f-e650-8de4dd35f2e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1033
        }
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "#matplotlib.use(\"TkAgg\")\n",
        "from matplotlib import pyplot as plt\n",
        "import itertools\n",
        "\n",
        "class Hopfield():\n",
        "    \"\"\"\n",
        "    implementation of a Hopfield network\n",
        "    \"\"\"\n",
        "\n",
        "    def fit(self,X,diag=True,bias=False):\n",
        "        self.X = X # patterns\n",
        "        self.N = X.shape[0]\n",
        "        self.D = X.shape[1] # number of neurons \n",
        "        self.diag = diag\n",
        "        self.bias = bias\n",
        "        self.maxIters = np.log(self.N)\n",
        "\n",
        "        self.learning()\n",
        "\n",
        "    def learning(self):\n",
        "        self.W = np.dot(self.X.T, self.X) / 1#/ self.N\n",
        "        if self.diag == False:\n",
        "            np.fill_diagonal(self.W, 0)\n",
        "\n",
        "    def recalls(self,Xmatrix,sync=True):\n",
        "        self.recalled = []\n",
        "        for idx, Xvector in enumerate(Xmatrix):\n",
        "            self.recalled.append(self.recall(Xvector=Xvector,Xindex=idx,sync=sync))\n",
        "\n",
        "    def recall(self,Xvector,Xindex=0,sync=True):\n",
        "        activations_prev = Xvector # t-1\n",
        "        activations_curr = 0 # t\n",
        "        self.sync = sync\n",
        "        \n",
        "        for iter in range(int(self.maxIters)+1):\n",
        "            activations_curr = self.update_neurons(activations_prev)\n",
        "            if np.all(activations_curr == activations_prev):\n",
        "                '''\n",
        "                try +1 iteration\n",
        "                '''\n",
        "                activations_curr = self.update_neurons(activations_prev)\n",
        "                # print(\"Pattern\",Xindex,\"converged in\",iter+1,\"iterations!\") # convergence\n",
        "                break\n",
        "            activations_prev = activations_curr\n",
        "        # print(sum(self.X[Xindex,:] == self.activations_prev)/self.D) # accuracy of obs\n",
        "        return activations_curr\n",
        "\n",
        "    def update_neurons(self,activations):\n",
        "        if self.sync == True: # synchronous / batch update\n",
        "            new = np.where(np.dot(self.W, activations.T).T > 0, 1,-1)\n",
        "        \n",
        "        else: # asynchronous / sequential update\n",
        "            new = activations.copy() # need copy due to argument\n",
        "            order = np.arange(self.D) #nr of nodes\n",
        "            # np.random.shuffle(order)\n",
        "            for i in order:\n",
        "                new[i] = np.where(np.dot(self.W[i,:], new.T) > 0, 1,-1)\n",
        "\n",
        "        return new\n",
        "\n",
        "    def getAttractors(self, Xmatrix,sync=True):\n",
        "        count = 0\n",
        "        # print(sync)\n",
        "        for p in Xmatrix:\n",
        "            potential_attractor = self.recall(Xvector=p,sync=sync)\n",
        "            if np.all(potential_attractor == p.T):\n",
        "                print(potential_attractor)\n",
        "                count += 1\n",
        "        print(\"#attractions = \", count)\n",
        "\n",
        "def visualize_img(pict, info=None):\n",
        "    plt.figure()\n",
        "    num = pict.shape[0]\n",
        "    if num==1:\n",
        "        img = pict[0].reshape(32, 32)\n",
        "        plt.imshow(img)\n",
        "        plt.title(info[0])\n",
        "    else:\n",
        "        f, ax = plt.subplots(1, num)\n",
        "        for i in range(num):\n",
        "            img = pict[i].reshape(32, 32)\n",
        "            ax[i].set_title(\"{}\".format(info[i]))\n",
        "            ax[i].imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "def distortData(data,pNoise):\n",
        "    noisyData = np.copy(data)\n",
        "    for i in range(data.shape[0]):\n",
        "        idx = np.arange(data.shape[1])\n",
        "        np.random.shuffle(idx)\n",
        "        idxNoise = idx[:int(data.shape[1]*pNoise)]\n",
        "        for j in idxNoise:\n",
        "            noisyData[i,j] = np.where(noisyData[i,j] == 1,-1,1)\n",
        "    return noisyData\n",
        "\n",
        "def capacity(data=\"random\",diag=True,sync=True,out=\"list\",noise=False,bias=False):\n",
        "    if data != \"random\":\n",
        "        for prob in [0.0, 0.05,0.10,0.15,0.20,0.25,0.30,0.40,0.50]:\n",
        "            noisyData = distortData(data,pNoise=prob)\n",
        "            # visualize_img(np.array([data[0],noisyData[0],data[1],noisyData[1],data[2],noisyData[2],data[3],noisyData[3]]), [\"p1\", \"p1Noisy\",\"p2\", \"p2Noisy\",\"p3\", \"p3Noisy\",\"p4\", \"p4Noisy\",])\n",
        "            accs = []\n",
        "            for i in range(data.shape[0]):\n",
        "                h = Hopfield()\n",
        "                trainData = data[:i+1:]\n",
        "                h.fit(X=trainData,diag=diag) #(i+1,1024)\n",
        "                noiseData = noisyData[:i+1:]\n",
        "                h.recalls(Xmatrix=noiseData,sync=sync)\n",
        "                \n",
        "                accuracy = 0\n",
        "                for t, r in zip(trainData, h.recalled):\n",
        "                    if np.all(t == r):\n",
        "                        accuracy += 1\n",
        "                accs.append(accuracy / noiseData.shape[0])\n",
        "            \n",
        "            if out == \"list\": \n",
        "                print(\"pNoise: \",prob,accs)\n",
        "            elif out == \"#stored\": # print number of stored patterns\n",
        "                print(\"pNoise: {} Stored patterns: {}\".format(prob,np.count_nonzero(np.array(accs) == 1.0)))\n",
        "    \n",
        "    else: # random patterns\n",
        "        # visualize_img(np.array([data[0],noisyData[0],data[1],noisyData[1],data[2],noisyData[2],data[3],noisyData[3]]), [\"p1\", \"p1Noisy\",\"p2\", \"p2Noisy\",\"p3\", \"p3Noisy\",\"p4\", \"p4Noisy\",])\n",
        "        N = 30\n",
        "        Accs = np.zeros(N)\n",
        "        n = 100 # in order to get averages\n",
        "        for i in range(n):\n",
        "            if bias == False:\n",
        "                randomData = np.where(np.random.normal(size=(N,100)) > 0, 1, -1)\n",
        "            else:\n",
        "                randomData = np.where(0.5+np.random.normal(size=(N,100)) > 0, 1, -1)\n",
        "            accs = []\n",
        "            for i in range(N):\n",
        "                h = Hopfield()\n",
        "                trainData = randomData[:i+1:]\n",
        "                h.fit(X=trainData,diag=diag) #(i+1,1024)\n",
        "                if noise == False:\n",
        "                    #h.recalls(Xmatrix=trainData,sync=sync)\n",
        "                    h.recalls(Xmatrix=trainData,sync=False)\n",
        "                else:\n",
        "                    # print(\"noise\")\n",
        "                    prob = 0.1\n",
        "                    noisyData = distortData(randomData,pNoise=prob)\n",
        "                    h.recalls(Xmatrix=noisyData,sync=sync)\n",
        "                \n",
        "                accuracy = 0\n",
        "                for t, r in zip(trainData, h.recalled):\n",
        "                    if np.all(t == r):\n",
        "                        accuracy += 1\n",
        "                accs.append(accuracy / trainData.shape[0])\n",
        "\n",
        "            Accs += np.array(accs)\n",
        "        Accs /= n\n",
        "\n",
        "        if out == \"list\": \n",
        "            print(Accs)\n",
        "        elif out == \"#stored\": # print number of stored patterns\n",
        "            print(\"Stored patterns: {}\".format(np.count_nonzero(np.array(Accs) == 1.0)))\n",
        "            print(Accs)\n",
        "            plt.figure()\n",
        "            plt.plot(Accs)\n",
        "            # plt.errorbar(frac_training, means, yerr=stds, fmt='o-') #,label='sigma=0.03')\n",
        "            # plt.legend(loc='upper right')\n",
        "            plt.xlabel('Number of patterns')\n",
        "            plt.ylabel('Accuracy')\n",
        "            plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "# ---------------------------------------------------------------------------------------------- #\n",
        "#  2.2. Hopfield network recall\n",
        "# ---------------------------------------------------------------------------------------------- #\n",
        "    print(\"\\n2.2. Hopfield network recall\")\n",
        "    x1 = [-1,-1, 1,-1, 1,-1,-1, 1]\n",
        "    x2 = [-1,-1,-1,-1,-1, 1,-1,-1]\n",
        "    x3 = [-1, 1, 1,-1,-1, 1,-1, 1]\n",
        "    X = np.array([x1,x2,x3])\n",
        "\n",
        "    h = Hopfield()\n",
        "    h.fit(X=X)\n",
        "    h.recalls(Xmatrix=X)\n",
        "# ---------------------------------------------------------------------------------------------- #\n",
        "#  3.1. Convergence and attractors\n",
        "# ---------------------------------------------------------------------------------------------- #\n",
        "    print(\"\\n3.1. Convergence and attractors\")\n",
        "    x1d = [ 1,-1, 1,-1, 1,-1,-1, 1]\n",
        "    x2d = [ 1, 1,-1,-1,-1, 1,-1,-1]\n",
        "    x3d = [ 1, 1, 1,-1, 1, 1,-1, 1]\n",
        "    Xd = np.array([x1d,x2d,x3d])\n",
        "# Apply the update rule repeatedly until you reach a stable fixed point.\n",
        "# Did all the patterns converge towards stored patterns?\n",
        "    h.recalls(Xmatrix=Xd)\n",
        "\n",
        "# How many attractors are there in this (256 possible combinations) network? Hint: automate the searching.\n",
        "    print(\"\\nAttractors\")\n",
        "    X256 = np.array(list(itertools.product([-1,1],repeat=8)))\n",
        "    h = Hopfield()\n",
        "    h.fit(X=X)\n",
        "    h.getAttractors(Xmatrix=X256,sync=False) # get 6 attractors with async and zeros on diag\n",
        "\n",
        "# What happens when you make the starting pattern even more dissimilar\n",
        "# to the stored ones (e.g. more than half is wrong)?\n",
        "    print(\"\\nDissimilar patterns:\")\n",
        "    x1d2 = [ 1, 1,-1, 1,-1,-1,-1, 1]\n",
        "    x2d2 = [ 1, 1, 1, 1, 1, 1,-1,-1]\n",
        "    x3d2 = [ 1,-1,-1, 1, 1,-1,-1, 1]\n",
        "    Xd2 = np.array([x1d2,x2d2,x3d2])\n",
        "    h.recalls(Xmatrix=Xd2)\n",
        "    # Do not get back the stored patterns\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------- #\n",
        "#  3.2. Sequential Update\n",
        "# ---------------------------------------------------------------------------------------------- #\n",
        "    print(\"\\nSequential update\")\n",
        "    SYNC = False\n",
        "    pictData = np.loadtxt('./pict.dat', delimiter=\",\", dtype=int).reshape(-1, 1024)\n",
        "    p1p2p3 = pictData[:3:] #(3,1024)\n",
        "    h = Hopfield()\n",
        "    h.fit(X=p1p2p3)\n",
        "    h.recalls(Xmatrix=p1p2p3,sync=SYNC)\n",
        "\n",
        "    # Check that the three patterns are stable.\n",
        "    res1 = []\n",
        "    for i in range(p1p2p3.shape[0]):\n",
        "        res1.append(h.recall(p1p2p3[i],sync=SYNC))\n",
        "    # visualize_img(np.array([p1p2p3[0],res1[0], p1p2p3[1],res1[1], p1p2p3[2],res1[2]]), [\"p1\", \"recalled p1\", \"p2\", \"recalled p2\", \"p3\", \"recalled p3\"])\n",
        "\n",
        "    # Can the network complete a degraded pattern? Try the pattern p10, which\n",
        "    # is a degraded version of p1, or p11 which is a mixture of p2 and p3.\n",
        "    p10p11 = pictData[-2:]\n",
        "\n",
        "    res1 = []\n",
        "    for i in range(p10p11.shape[0]):\n",
        "        res1.append(h.recall(p10p11[i],sync=SYNC)) #(1024,1)\n",
        "    # visualize_img(np.array([p1p2p3[0],p10p11[0],res1[0],p1p2p3[1],p1p2p3[2],p10p11[1],res1[1]]), [\"p1\", \"p10\",\"recalled p10\", \"p2\", \"p3\", \"p11\", \"recalled p11\"])\n",
        "    # p10 == p1 with batch, not seq. p11 == p2 with seq, otherwise nothing.\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------- #\n",
        "#  3.3. Energy\n",
        "# ---------------------------------------------------------------------------------------------- #\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------- #\n",
        "#  3.4. Distortion Resistance\n",
        "# ---------------------------------------------------------------------------------------------- #\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------- #\n",
        "#  3.5. Capacity\n",
        "# ---------------------------------------------------------------------------------------------- #\n",
        "    print(\"Capacity\")\n",
        "# How many patterns could safely be stored? Was the drop in performance gradual or abrupt?\n",
        "\n",
        "    # capacity(data=pictData) # three\n",
        "    # capacity(data=pictData,sync=False) # three\n",
        "\n",
        "# Try to repeat this with learning a few random patterns\n",
        "# instead of the pictures and see if you can store more.\n",
        "\n",
        "    # randomData = np.where(np.random.normal(size=(11,1024)) > 0, 1, -1)\n",
        "    # capacity(data=randomData)\n",
        "    # capacity(data=randomData,sync=False)\n",
        "\n",
        "# It has been shown that the capacity of a Hopfield network\n",
        "# is around 0.138N. How do you explain the difference\n",
        "# between random patterns and the pictures?\n",
        "\n",
        "# What happens with the number of stable patterns as more are learned?\n",
        "    # They decrease and then increase (for batch and sequential)\n",
        "\n",
        "    capacity(data=\"random\",out=\"#stored\",noise=False)\n",
        "    # capacity(data=\"random\",out=\"#stored\",noise=False,sync=False)\n",
        "\n",
        "# What happens if convergence to the pattern from a noisy version (a few fliipped units)\n",
        "# is used? What does the different behavior for large number of patterns mean?\n",
        "    \n",
        "    # They decrease (for batch and sequential)\n",
        "    # capacity(data=\"random\",out=\"#stored\",noise=True)\n",
        "    # capacity(data=\"random\",out=\"#stored\",noise=True,sync=False)\n",
        "\n",
        "# Remove self-connections. What is the maximum number of retrievable patterns for this network?\n",
        "    \n",
        "    # capacity(data=\"random\",out=\"#stored\",noise=True,diag=False) # 4 patterns on average / 6 with self connections\n",
        "    \n",
        "    # capacity(data=\"random\",out=\"#stored\",noise=True,diag=False,bias=True) # 4 even less patterns\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "2.2. Hopfield network recall\n",
            "\n",
            "3.1. Convergence and attractors\n",
            "\n",
            "Attractors\n",
            "[-1 -1 -1 -1 -1  1 -1 -1]\n",
            "[-1 -1 -1 -1  1 -1 -1 -1]\n",
            "[-1 -1  1 -1 -1 -1 -1  1]\n",
            "[-1 -1  1 -1 -1  1 -1  1]\n",
            "[-1 -1  1 -1  1 -1 -1  1]\n",
            "[-1  1  1 -1 -1  1 -1  1]\n",
            "[ 1 -1 -1  1 -1  1  1 -1]\n",
            "[ 1 -1 -1  1  1 -1  1 -1]\n",
            "[ 1 -1  1  1  1 -1  1  1]\n",
            "[ 1  1 -1  1 -1 -1  1 -1]\n",
            "[ 1  1 -1  1 -1  1  1 -1]\n",
            "[ 1  1 -1  1  1 -1  1 -1]\n",
            "[ 1  1  1  1 -1  1  1  1]\n",
            "[ 1  1  1  1  1 -1  1  1]\n",
            "#attractions =  14\n",
            "\n",
            "Dissimilar patterns:\n",
            "\n",
            "Sequential update\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-73f1e2a685fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSequential update\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mSYNC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mpictData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./pict.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0mp1p2p3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpictData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#(3,1024)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHopfield\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    614\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    615\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: ./pict.dat not found."
          ]
        }
      ]
    }
  ]
}